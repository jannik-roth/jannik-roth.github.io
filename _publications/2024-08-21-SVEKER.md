---
title: "Machine learning models with distinct Shapley value explanations decouple feature attribution and interpretation for chemical compound predictions"
collection: publications
category: manuscripts
# permalink: /publication/2009-10-01-paper-title-number-1
# excerpt: 'This paper is about the number 1. The number 2 is left for future work.'
date: 2024-08-21
venue: 'Cell Reports Physical Science'
# slidesurl: 'http://academicpages.github.io/files/slides1.pdf'
paperurl: 'https://doi.org/10.1016/j.xcrp.2024.102110'
# bibtexurl: 'http://academicpages.github.io/files/bibtex1.bib'
# citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---

Explaining black box predictions of machine learning (ML) models is a topical issue in artificial intelligence (AI) research. For the identification of features determining predictions, the Shapley value formalism originally developed in game theory is widely used in different fields. Typically, Shapley values quantifying feature contributions to predictions need to be approximated in machine learning. We introduce a framework for the calculation of exact Shapley values for 4 kernel functions used in support vector machine (SVM) models and analyze consistently accurate compound activity predictions based on exact Shapley values. Dramatic changes in feature contributions are detected depending on the kernel function, leading to mostly distinct explanations of predictions of the same test compounds. Very different feature contributions yield comparable predictions, which complicate numerical and graphical model explanation and decouple feature attribution and human interpretability.
